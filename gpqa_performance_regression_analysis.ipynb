{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# GPQA-D Performance Regression Analysis\n",
    "\n",
    "This notebook performs reverse regression analysis to understand how GPQA-D performance improves over time.\n",
    "\n",
    "**Key Questions:**\n",
    "1. How much does performance improve per year **holding price constant** (by price bin)?\n",
    "2. How much does performance improve per year **without controlling for price** (overall trend)?\n",
    "\n",
    "**Methodology:**\n",
    "- Use logit-transformed GPQA-D scores: logit(p) = log(p / (1-p))\n",
    "- Linear regression of logit(GPQA-D) vs time\n",
    "- Focus on Pareto frontier (best models in each price bin over time)\n",
    "- Report annual improvement rates in both logit units and approximate percentage points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from matplotlib.dates import DateFormatter\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('data/price_reduction_models.csv')\n",
    "\n",
    "# Convert Release Date to datetime\n",
    "df['Release Date'] = pd.to_datetime(df['Release Date'])\n",
    "\n",
    "# Clean GPQA-D column (epoch_gpqa) - convert percentage strings to floats\n",
    "df['GPQA_D'] = df['epoch_gpqa'].astype(str).str.replace('%', '').astype(float)\n",
    "\n",
    "# Clean Benchmark Cost USD - convert string with $ and commas to float\n",
    "df['Price'] = df['Benchmark Cost USD'].astype(str).str.replace('[$,]', '', regex=True)\n",
    "df['Price'] = pd.to_numeric(df['Price'], errors='coerce')\n",
    "\n",
    "# Filter out rows with missing data\n",
    "df_clean = df[['Model', 'Release Date', 'GPQA_D', 'Price']].dropna()\n",
    "df_clean = df_clean[df_clean['Price'] > 0]\n",
    "\n",
    "print(f\"Total models with complete data: {len(df_clean)}\")\n",
    "print(f\"Date range: {df_clean['Release Date'].min()} to {df_clean['Release Date'].max()}\")\n",
    "print(f\"GPQA-D range: {df_clean['GPQA_D'].min():.1f}% to {df_clean['GPQA_D'].max():.1f}%\")\n",
    "print(f\"Price range: ${df_clean['Price'].min():.2f} to ${df_clean['Price'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define logit transformation functions\n",
    "def logit(p):\n",
    "    \"\"\"Convert probability to logit scale\"\"\"\n",
    "    # Clip values to avoid log(0) or log(infinity)\n",
    "    p_clipped = np.clip(p, 0.001, 0.999)\n",
    "    return np.log(p_clipped / (1 - p_clipped))\n",
    "\n",
    "def inverse_logit(logit_val):\n",
    "    \"\"\"Convert logit back to probability\"\"\"\n",
    "    return 1 / (1 + np.exp(-logit_val))\n",
    "\n",
    "# Add logit column (convert percentage to decimal first)\n",
    "df_clean['GPQA_D_logit'] = logit(df_clean['GPQA_D'] / 100)\n",
    "\n",
    "# Add ordinal date for regression\n",
    "df_clean['Date_Ordinal'] = df_clean['Release Date'].map(datetime.toordinal)\n",
    "\n",
    "print(\"Logit transformation complete.\")\n",
    "print(f\"Logit range: {df_clean['GPQA_D_logit'].min():.2f} to {df_clean['GPQA_D_logit'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define price bins - same as in previous analysis\n",
    "price_percentiles = [0, 33, 67, 100]\n",
    "price_bins = np.percentile(df_clean['Price'], price_percentiles)\n",
    "\n",
    "# Create bin labels\n",
    "bin_labels = [\n",
    "    f'Low Price (${price_bins[0]:.2f}-${price_bins[1]:.2f})',\n",
    "    f'Mid Price (${price_bins[1]:.2f}-${price_bins[2]:.2f})',\n",
    "    f'High Price (${price_bins[2]:.2f}-${price_bins[3]:.2f})'\n",
    "]\n",
    "\n",
    "# Assign bins\n",
    "df_clean['Price_Bin'] = pd.cut(df_clean['Price'], bins=price_bins, labels=bin_labels, include_lowest=True)\n",
    "\n",
    "print(\"\\nPrice bins defined:\")\n",
    "print(df_clean['Price_Bin'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Regression Analysis: Performance Improvement Over Time\n",
    "\n",
    "We perform linear regression of logit(GPQA-D) vs time for:\n",
    "1. Each price bin (controlling for price)\n",
    "2. All models combined (not controlling for price)\n",
    "\n",
    "We can choose to use:\n",
    "- **Pareto frontier only**: Best models in each bin over time\n",
    "- **All models**: Every model in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_regression_analysis(df, use_pareto_only=True, min_date=None):\n",
    "    \"\"\"\n",
    "    Perform regression analysis of logit(GPQA-D) vs time.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        Input data with columns: Release Date, GPQA_D, GPQA_D_logit, Price, Price_Bin, Date_Ordinal\n",
    "    use_pareto_only : bool\n",
    "        If True, use only Pareto frontier (best models over time in each bin)\n",
    "        If False, use all models\n",
    "    min_date : datetime or None\n",
    "        Filter to models released on or after this date\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    results_df : DataFrame\n",
    "        Summary table with regression results for each price bin and overall\n",
    "    \"\"\"\n",
    "    \n",
    "    df_work = df.copy()\n",
    "    \n",
    "    # Apply date filter if specified\n",
    "    if min_date is not None:\n",
    "        if isinstance(min_date, str):\n",
    "            min_date = pd.to_datetime(min_date)\n",
    "        df_work = df_work[df_work['Release Date'] >= min_date]\n",
    "    \n",
    "    # Sort by date\n",
    "    df_work = df_work.sort_values('Release Date')\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Analyze each price bin\n",
    "    for bin_label in sorted(df_work['Price_Bin'].dropna().unique()):\n",
    "        df_bin = df_work[df_work['Price_Bin'] == bin_label].copy()\n",
    "        \n",
    "        if len(df_bin) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Get Pareto frontier if requested\n",
    "        if use_pareto_only:\n",
    "            df_bin['Is_Best'] = df_bin['GPQA_D'].cummax() == df_bin['GPQA_D']\n",
    "            df_analysis = df_bin[df_bin['Is_Best']].copy()\n",
    "        else:\n",
    "            df_analysis = df_bin.copy()\n",
    "        \n",
    "        if len(df_analysis) < 2:\n",
    "            continue\n",
    "        \n",
    "        # Perform regression\n",
    "        X = df_analysis['Date_Ordinal'].values.reshape(-1, 1)\n",
    "        y = df_analysis['GPQA_D_logit'].values\n",
    "        \n",
    "        model = LinearRegression().fit(X, y)\n",
    "        r_squared = model.score(X, y)\n",
    "        \n",
    "        # Calculate annual improvement rate in logit units\n",
    "        annual_improvement_logit = model.coef_[0] * 365\n",
    "        \n",
    "        # Convert to approximate percentage points per year at mean performance\n",
    "        mean_gpqa = df_analysis['GPQA_D'].mean()\n",
    "        mean_logit = logit(mean_gpqa / 100)\n",
    "        future_logit = mean_logit + annual_improvement_logit\n",
    "        future_prob = inverse_logit(future_logit) * 100\n",
    "        annual_improvement_pct = future_prob - mean_gpqa\n",
    "        \n",
    "        # Calculate 95% confidence interval for slope\n",
    "        n = len(X)\n",
    "        y_pred = model.predict(X)\n",
    "        residuals = y - y_pred\n",
    "        mse = np.sum(residuals**2) / (n - 2)\n",
    "        se = np.sqrt(mse / np.sum((X - np.mean(X))**2))\n",
    "        t_val = stats.t.ppf(0.975, n - 2)\n",
    "        ci_lower_logit = (model.coef_[0] - t_val * se) * 365\n",
    "        ci_upper_logit = (model.coef_[0] + t_val * se) * 365\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'Category': str(bin_label),\n",
    "            'N_Models': len(df_analysis),\n",
    "            'Date_Range': f\"{df_analysis['Release Date'].min().strftime('%Y-%m-%d')} to {df_analysis['Release Date'].max().strftime('%Y-%m-%d')}\",\n",
    "            'GPQA-D_Range': f\"{df_analysis['GPQA_D'].min():.1f}% to {df_analysis['GPQA_D'].max():.1f}%\",\n",
    "            'Mean_GPQA-D': f\"{mean_gpqa:.1f}%\",\n",
    "            'Annual_Improvement_Logits': annual_improvement_logit,\n",
    "            'Annual_Improvement_PctPts': annual_improvement_pct,\n",
    "            'CI_Lower_Logits': ci_lower_logit,\n",
    "            'CI_Upper_Logits': ci_upper_logit,\n",
    "            'R_Squared': r_squared,\n",
    "            'Price_Range': f\"${df_analysis['Price'].min():.2f} to ${df_analysis['Price'].max():.2f}\"\n",
    "        })\n",
    "    \n",
    "    # Analyze overall (not controlling for price)\n",
    "    if use_pareto_only:\n",
    "        df_work['Is_Overall_Best'] = df_work['GPQA_D'].cummax() == df_work['GPQA_D']\n",
    "        df_overall = df_work[df_work['Is_Overall_Best']].copy()\n",
    "    else:\n",
    "        df_overall = df_work.copy()\n",
    "    \n",
    "    if len(df_overall) >= 2:\n",
    "        X = df_overall['Date_Ordinal'].values.reshape(-1, 1)\n",
    "        y = df_overall['GPQA_D_logit'].values\n",
    "        \n",
    "        model = LinearRegression().fit(X, y)\n",
    "        r_squared = model.score(X, y)\n",
    "        \n",
    "        annual_improvement_logit = model.coef_[0] * 365\n",
    "        \n",
    "        mean_gpqa = df_overall['GPQA_D'].mean()\n",
    "        mean_logit = logit(mean_gpqa / 100)\n",
    "        future_logit = mean_logit + annual_improvement_logit\n",
    "        future_prob = inverse_logit(future_logit) * 100\n",
    "        annual_improvement_pct = future_prob - mean_gpqa\n",
    "        \n",
    "        # Calculate 95% confidence interval\n",
    "        n = len(X)\n",
    "        y_pred = model.predict(X)\n",
    "        residuals = y - y_pred\n",
    "        mse = np.sum(residuals**2) / (n - 2)\n",
    "        se = np.sqrt(mse / np.sum((X - np.mean(X))**2))\n",
    "        t_val = stats.t.ppf(0.975, n - 2)\n",
    "        ci_lower_logit = (model.coef_[0] - t_val * se) * 365\n",
    "        ci_upper_logit = (model.coef_[0] + t_val * se) * 365\n",
    "        \n",
    "        results.append({\n",
    "            'Category': 'Overall (No Price Control)',\n",
    "            'N_Models': len(df_overall),\n",
    "            'Date_Range': f\"{df_overall['Release Date'].min().strftime('%Y-%m-%d')} to {df_overall['Release Date'].max().strftime('%Y-%m-%d')}\",\n",
    "            'GPQA-D_Range': f\"{df_overall['GPQA_D'].min():.1f}% to {df_overall['GPQA_D'].max():.1f}%\",\n",
    "            'Mean_GPQA-D': f\"{mean_gpqa:.1f}%\",\n",
    "            'Annual_Improvement_Logits': annual_improvement_logit,\n",
    "            'Annual_Improvement_PctPts': annual_improvement_pct,\n",
    "            'CI_Lower_Logits': ci_lower_logit,\n",
    "            'CI_Upper_Logits': ci_upper_logit,\n",
    "            'R_Squared': r_squared,\n",
    "            'Price_Range': f\"${df_overall['Price'].min():.2f} to ${df_overall['Price'].max():.2f}\"\n",
    "        })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Results: Pareto Frontier Only\n",
    "\n",
    "This analysis uses only the best models in each price bin over time (Pareto frontier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform regression analysis using Pareto frontier only\n",
    "results_pareto = perform_regression_analysis(\n",
    "    df_clean,\n",
    "    use_pareto_only=True,\n",
    "    min_date=datetime(2024, 4, 1)\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"REGRESSION ANALYSIS: PARETO FRONTIER ONLY\")\n",
    "print(\"Performance Improvement Over Time (Logit Scale)\")\n",
    "print(\"=\"*100 + \"\\n\")\n",
    "\n",
    "# Display with nice formatting\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "display(results_pareto)\n",
    "\n",
    "# Save to CSV\n",
    "results_pareto.to_csv('results/gpqa_regression_pareto.csv', index=False)\n",
    "print(\"\\nResults saved to: results/gpqa_regression_pareto.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Results: All Models\n",
    "\n",
    "This analysis uses all models in the dataset, not just the Pareto frontier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform regression analysis using all models\n",
    "results_all = perform_regression_analysis(\n",
    "    df_clean,\n",
    "    use_pareto_only=False,\n",
    "    min_date=datetime(2024, 4, 1)\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"REGRESSION ANALYSIS: ALL MODELS\")\n",
    "print(\"Performance Improvement Over Time (Logit Scale)\")\n",
    "print(\"=\"*100 + \"\\n\")\n",
    "\n",
    "display(results_all)\n",
    "\n",
    "# Save to CSV\n",
    "results_all.to_csv('results/gpqa_regression_all_models.csv', index=False)\n",
    "print(\"\\nResults saved to: results/gpqa_regression_all_models.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Formatted Summary Table\n",
    "\n",
    "A clean, formatted version of the Pareto frontier results for presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create formatted summary table\n",
    "summary_table = results_pareto.copy()\n",
    "\n",
    "# Round numerical columns\n",
    "summary_table['Annual_Improvement_Logits'] = summary_table['Annual_Improvement_Logits'].round(3)\n",
    "summary_table['Annual_Improvement_PctPts'] = summary_table['Annual_Improvement_PctPts'].round(2)\n",
    "summary_table['R_Squared'] = summary_table['R_Squared'].round(3)\n",
    "\n",
    "# Create confidence interval column\n",
    "summary_table['95% CI (Logits/yr)'] = summary_table.apply(\n",
    "    lambda row: f\"[{row['CI_Lower_Logits']:.3f}, {row['CI_Upper_Logits']:.3f}]\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Select and rename columns for presentation\n",
    "presentation_table = summary_table[[\n",
    "    'Category',\n",
    "    'N_Models',\n",
    "    'Mean_GPQA-D',\n",
    "    'Annual_Improvement_Logits',\n",
    "    'Annual_Improvement_PctPts',\n",
    "    '95% CI (Logits/yr)',\n",
    "    'R_Squared',\n",
    "    'GPQA-D_Range'\n",
    "]].copy()\n",
    "\n",
    "presentation_table.columns = [\n",
    "    'Category',\n",
    "    'N',\n",
    "    'Mean GPQA-D',\n",
    "    'Annual Improvement (logits/yr)',\n",
    "    'Annual Improvement (% pts/yr)',\n",
    "    '95% CI (logits/yr)',\n",
    "    'R²',\n",
    "    'GPQA-D Range'\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"SUMMARY: GPQA-D Performance Improvement Rates (Pareto Frontier)\")\n",
    "print(\"=\"*120 + \"\\n\")\n",
    "\n",
    "display(presentation_table)\n",
    "\n",
    "# Save formatted table\n",
    "presentation_table.to_csv('results/gpqa_regression_summary.csv', index=False)\n",
    "print(\"\\nFormatted summary saved to: results/gpqa_regression_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "Extract and display key insights from the regression analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\"*100 + \"\\n\")\n",
    "\n",
    "# Compare price-controlled vs uncontrolled improvement rates\n",
    "overall_row = results_pareto[results_pareto['Category'] == 'Overall (No Price Control)'].iloc[0]\n",
    "price_bin_rows = results_pareto[results_pareto['Category'] != 'Overall (No Price Control)']\n",
    "\n",
    "print(\"1. OVERALL IMPROVEMENT (Not Controlling for Price):\")\n",
    "print(f\"   - Annual improvement: {overall_row['Annual_Improvement_Logits']:.3f} logits/yr\")\n",
    "print(f\"   - Approximate: {overall_row['Annual_Improvement_PctPts']:.2f} percentage points/yr\")\n",
    "print(f\"   - R² = {overall_row['R_Squared']:.3f}\")\n",
    "print(f\"   - Based on {overall_row['N_Models']} record-breaking models\\n\")\n",
    "\n",
    "print(\"2. IMPROVEMENT BY PRICE BIN (Controlling for Price):\")\n",
    "for idx, row in price_bin_rows.iterrows():\n",
    "    print(f\"\\n   {row['Category']}:\")\n",
    "    print(f\"   - Annual improvement: {row['Annual_Improvement_Logits']:.3f} logits/yr\")\n",
    "    print(f\"   - Approximate: {row['Annual_Improvement_PctPts']:.2f} percentage points/yr\")\n",
    "    print(f\"   - R² = {row['R_Squared']:.3f}\")\n",
    "    print(f\"   - Based on {row['N_Models']} models\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*100)\n",
    "\n",
    "# Compare improvement rates across price bins\n",
    "print(\"\\n3. COMPARISON ACROSS PRICE BINS:\")\n",
    "sorted_bins = price_bin_rows.sort_values('Annual_Improvement_Logits', ascending=False)\n",
    "print(f\"\\n   Fastest improving: {sorted_bins.iloc[0]['Category']}\")\n",
    "print(f\"   - {sorted_bins.iloc[0]['Annual_Improvement_Logits']:.3f} logits/yr\")\n",
    "print(f\"   - {sorted_bins.iloc[0]['Annual_Improvement_PctPts']:.2f} percentage points/yr\")\n",
    "\n",
    "print(f\"\\n   Slowest improving: {sorted_bins.iloc[-1]['Category']}\")\n",
    "print(f\"   - {sorted_bins.iloc[-1]['Annual_Improvement_Logits']:.3f} logits/yr\")\n",
    "print(f\"   - {sorted_bins.iloc[-1]['Annual_Improvement_PctPts']:.2f} percentage points/yr\")\n",
    "\n",
    "# Calculate ratio\n",
    "ratio = sorted_bins.iloc[0]['Annual_Improvement_Logits'] / sorted_bins.iloc[-1]['Annual_Improvement_Logits']\n",
    "print(f\"\\n   Ratio: {ratio:.2f}x faster improvement\\n\")\n",
    "\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Interpretation Guide\n",
    "\n",
    "**Annual Improvement (logits/yr)**: The slope of the regression line in logit space. Higher values = faster improvement.\n",
    "\n",
    "**Annual Improvement (% pts/yr)**: Approximate improvement in percentage points per year, calculated at the mean performance level for that category. This is easier to interpret than logit units.\n",
    "\n",
    "**R²**: Coefficient of determination. Higher values (closer to 1.0) indicate the linear trend explains more variance in the data.\n",
    "\n",
    "**Controlling for Price**: When we analyze by price bin, we're holding price roughly constant and measuring how performance improves over time at that price level.\n",
    "\n",
    "**Not Controlling for Price**: The overall trend includes all models regardless of price, so it captures both:\n",
    "- Performance improvements at all price levels\n",
    "- The effect of higher-priced models potentially having better performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
